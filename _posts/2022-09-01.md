---
title: 'Quick Notes: Variation of GAN (Stacked GAN, StackGAN++, PA-GAN)'
date: 2022-09-01
permalink: /posts/2022/09/blog-post-18/
comments: true
tags:
  - DL
  - GAN
---

For the past 4 months, I have been working on cardiovascular disease risk prediction. Through this, I come up with an idea to utilize GAN to learn in a progressive way and decide to write a paper on this topic(Sry, I can't talk much about my idea in details). Then, I began doing background research and found three related topic. In this post, I will give summarizations of these topic. 

Stacked(or progressive) GAN is kind of a new topic, related paper has been published starting from 2016 ( plz feel free to leave msg, if you know other related paper which is earlier than 2016, or you know other related interesting topics). The existing related research can be divided into 2 groups, one is to build the model structure hierarchically, e.g. Stacked GAN, StackGAN++, the model architecture resembles stacking(ensemble learning). The other is controlling the input to be imported in a progressive way. For PA-GAN, the input has been gradually augmented by increasing the sample dimensionality to increase task difficulty of D.

**Table 1.**

| Paper(Topic)        | Publication Year | Goal  |
| ------------- |:-------------:| -----:|
| Stacked GAN      | 2017 | generate high-quality image |
| StackGAN++      | 2018      |  generate high-resolution photo image  |
| PA-GAN | 2019      |  stablize training process   |

# GAN
There are a lot of excellent blogs explaining the principles of GAN (e.g. [From GAN to WGAN](https://lilianweng.github.io/lil-log/2017/08/20/from-GAN-to-WGAN.html)). So I won't cover related details in this post. Before explaining the 3 GAN variations, I'd like to recall the shortcomings of GAN.

## Disadvantages of GAN
**Choosing which to win?** The training process can be viewed as a competition between Generator(G) and Discriminator(D): iterations of attack and defend. Through such process, both the ability of G and D has been enhanced. In my opinion, this can't reach a win-win situation. Imagine if G & D runs in a pretty tight race, then neither the simulated results of G would be of high-quality, nor the identification ability of D would be good enough. So there must be a winner between the two. Whether to choose G over D or in the opposite way, I think it depends on the specific goal of the project. 

**Unstable training process and vanishing gradient:** I think these two are somehow correlated. The support of real data and generated ones usually lie on low dimensional manifolds and are usually disjoint --> D often learns much faster than G --> Its loss function gradient quickly becomes 0, meaning it can't provide accurate and continuous feedback to G. That's how these two problems come out. One solution is to enforce the model learning in a progressive process, can be viewed as controlling the learning speed, which is the main idea in the following 3 paper.

**Mode collapse:** GAN has been mainly used for generating high quality simulated images, but its generations are usually limited within certain scope, meaning G can't produce diverse results.
{% capture notice-2 %}
Tips: the reason to input a random noise z to G is that z can alleviate mode collapse to certain extent, because of its randomness. (Plz correct me, if I'm not right.)
{% endcapture %}
<div class="notice--info">{{ notice-2 | markdownify }}</div>


<p float="left">
	<img src="/images/disGAN.png" width="400" />
</p>

**Figure 1. Disadvantages**

# Stacked Generative Adversarial Networks, SGAN

SGAN aims to generate high-quality image. To me, the idea of SGAN is quite brilliant. Because instead of learning the whole data directly, it hierarchically extracts information from the data through encoders, generate representation level by level, then let G learns these representation in a top-down way. From my perspective, high-level image representation contains more details than low-level ones. So G can generate more realistic and specific low-level samples based on high-level representation. Also, by importing data level-by-level, I think this can control the speed of Dâ€™s learning speed, which is helpful for stablizing the training process. `These are all personal opinions, plz correct me, if something is wrong. Thx :)`

<p float="left">
	<img src="/images/SGAN1.png" width="400" />
</p>

**Figure 2. SGAN Framework**


Next, I will dive into details of SGAN. The training stage can be divided into 3 sections, which is shown in Table 2. The first stage is to use encoders(CNN in this paper) to extract level-wise information from images in a bottom-up direction. The 2nd step is to independently training each G<sub>i</sub> to predict level-wise representation <img src="https://latex.codecogs.com/svg.latex?  \widehat{h_{i}}" />, by taking a noise vector z<sub>i</sub> and higher level representation h<sub>i+1</sub> as input, and let D<sub>i</sub> judge the quality of <img src="https://latex.codecogs.com/svg.latex?  \widehat{h_{i}}" />. 

**Attention:** the higher level feature h<sub>i+1</sub> is the outcome of encoder E<sub>i</sub>. To ensure <img src="https://latex.codecogs.com/svg.latex?  \widehat{h_{i}}" /> indeed masters the knowledge in h<sub>i+1</sub>, a conditional loss has been introduced(shown in Table 2). 

Finally, here comes with the 3rd training stage: jointly training. All Gs have been connected in a top-to-bottom direction, forming an end-to-end architecture. Each G produce an intermediate representation and then pass it to the next G as an input. So here <img src="https://latex.codecogs.com/svg.latex?  \widehat{h_{i}} = G(\widehat{h}_{i+1}, z_i)" />.

Besides, it is stated in the paper that simply adding the conditional loss indeed ensures G<sub>i</sub> learns from h<sub>i+1</sub>, but G<sub>i</sub> tends to ignore the random noise z<sub>i</sub>. So how to avoid this? Let's first recall the reason for adding z. 

It is used to **increase diversity** in results. So we want <img src="https://latex.codecogs.com/svg.latex?  \widehat{h_{i}}" /> to be as diverse as possible when conditioned on h<sub>i+1</sub>, which is equivalent to maximize a conditional entropy <img src="https://latex.codecogs.com/svg.latex?  H(\widehat{h_{i}}|h_{i+1})"> to check if <img src="https://latex.codecogs.com/svg.latex?  \widehat{h_{i}}" /> is sufficiently diverse when conditioned on h<sub>i+1</sub>. That's why a entropy loss has been added. (More details are articulated in the original paper, section 3.4)

**Table 2.**  

| **Training Step**        | **Formula Details**    |**Loss Function**  | **Why Using This Loss Function**  |
| ------------- |:-------------:| -----:| ------------:|
| 1. Encoders learn level-wise intermediate representations from bottom to top(Fig 3. left blue section, arrow direction) | ![](/images/SGANf1.png)| | |
| 2. Independent training of each G(Fig 3. central section)    | ![](/images/SGANf2.png) |  **Conditional loss:** ![](/images/SGANf5.png) |Impose G to learn high-level conditional representation|
|||**Adversarial loss:** ![](/images/SGANf4.png)| Discriminator identify real data h<sub>i</sub> and generated ones <img src="https://latex.codecogs.com/svg.latex?  \widehat{h_{i}}">|
| 3. Jointly end-to-end training of all Gs(Fig 3. central section, top to bottom, arrow direction)| ![](/images/SGANf3.png) | **entropy loss:** ![](/images/SGANf6.png)| Maintain diverse generations|
| **Testing Step**        | **Maintain Results Diversity**  |  |   |
| ------------- |:-------------:| -----:| ------------:|
| Top-to-bottom generating simulated images, no info. needed from encoder(Fig 3. right section)| By adding random noise z to each level|||




<p float="left">
	<img src="/images/SGAN2.png" width="300" />
</p>

**Figure 3. SGAN Final Loss Function(Source: [1])**

{% capture notice-2 %}
**N:** # stacks, **h<sub>i</sub>:** level-wise representation, **x:** input images, h<sub>0</sub> = x, **y:** classification label, h<sub>N</sub> = y, **E<sub>i</sub>**, **G<sub>i</sub>**, **D<sub>i</sub>:** the ith encoder, generator, discriminator
{% endcapture %}
<div class="notice--info">{{ notice-2 | markdownify }}</div>


<p float="left">
	<img src="/images/SGAN.png" width="1000" />
</p>

**Figure 4. SGAN Framework Details(Source: [1])**

# StackGAN++

**TBA...**

# PA-GAN

**TBA...**

<p float="center"><img src="https://latex.codecogs.com/svg.latex?  " title="p" /></p>


{% capture notice-2 %}
{% endcapture %}
<div class="notice--warning">{{ notice-2 | markdownify }}</div>


{% capture notice-2 %}
{% endcapture %}
<div class="notice--info">{{ notice-2 | markdownify }}</div>


Reference
========

[1]. Xun H., Yixuan L. et al. Stacked Generative Adversarial Networks, CVPR(2017)

[2]. [SGAN Github Repo](https://github.com/xunhuang1995/SGAN)

[3]. https://medium.com/@jonathan_hui/gan-stacked-generative-adversarial-networks-sgan-d9449ac63db8

[4]. Han Zh., Tao X. et al. StackGAN++: Realistic Image Synthesis with Stacked Generative Adversarial Networks

[5]. PA-GAN: Improving GAN Training by Progressive Augmentation


------